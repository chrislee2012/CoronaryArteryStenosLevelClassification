{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import pydicom as dicom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from numpy import nan as Nan\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Copy data without DICOM viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wether_patient_has_records(path_to_patient_folder, get_names_of_records=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        get_names_of_records (bool): wether return names of record files\n",
    "        \n",
    "    Returns:\n",
    "        bool: Retuns value. True if patient folder contains the records and False otherwise. \n",
    "        or\n",
    "        tuple (bool, list): returns bool and names of the record files for the patient.  \n",
    "    \"\"\"\n",
    "    names_of_the_records = [x for x in os.listdir(path_to_patient_folder) if 'doc' in x or 'xlsx' in x]\n",
    "    if get_names_of_records:\n",
    "        return len(names_of_the_records) >=1, names_of_the_records\n",
    "    else:\n",
    "        return len(names_of_the_records) >=1\n",
    "\n",
    "def check_wether_patient_has_image_data(path_to_patient_folder):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        bool : Returns True if patient folder contatin image data and False otherwise\n",
    "    \"\"\"\n",
    "    names_of_the_records = [x for x in os.listdir(path_to_patient_folder) if 'DICOMOBJ' in x]\n",
    "    return len(names_of_the_records) >= 1\n",
    "\n",
    "def get_structure_of_the_dataset(path_to_dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns:\n",
    "        dict :  keys - patient names(str): values (list of strings) - paths to the images and records\n",
    "                                                    \n",
    "    \"\"\"\n",
    "    patients_database = {}\n",
    "    \n",
    "    reports_folders = [x for x in os.listdir(path_to_dataset) if not any(i in x for i in\n",
    "                            ['System', 'BIN', '$.BIN', 'Autorun.inf','Seagate', 'SeagateExpansion.ico', \n",
    "                             'Start_Here_Mac.app', 'Start_Here_Win.exe', 'Warranty.pdf'])]\n",
    "                       #'System' not in x and 'BIN' not in x]\n",
    "    for report_folder in tqdm(reports_folders):\n",
    "        patients_per_folder = os.listdir(os.path.join(path_to_dataset, report_folder))\n",
    "        \n",
    "        for patient in patients_per_folder:\n",
    "            \n",
    "            files_in_patient_folder = os.listdir(os.path.join(path_to_dataset, report_folder, patient))\n",
    "            \n",
    "            if check_wether_patient_has_image_data(os.path.join(path_to_dataset, report_folder, patient)):\n",
    "                patient_images = os.listdir(os.path.join(path_to_dataset, report_folder, patient, 'DICOMOBJ'))\n",
    "                patient_images_paths = [os.path.join(path_to_dataset, report_folder, patient, 'DICOMOBJ', x) \n",
    "                                 for x in patient_images]\n",
    "            else:\n",
    "                patient_images = []\n",
    "                patient_images_paths = []\n",
    "            _, patient_records = check_wether_patient_has_records(\n",
    "                                      os.path.join(path_to_dataset, report_folder, patient), \n",
    "                                      get_names_of_records=True)\n",
    "            patient_records_paths = [os.path.join(path_to_dataset, report_folder, patient, x) for x in patient_records]\n",
    "            patients_database[patient] = []\n",
    "            patients_database[patient] += patient_records_paths\n",
    "            patients_database[patient] += patient_images_paths\n",
    "    \n",
    "    return patients_database\n",
    "\n",
    "def copy_dataset(patients_database, path_to_copy):\n",
    "    \"\"\"\n",
    "    Copy only image data and records without DICOM viewer program\n",
    "    Args:\n",
    "        patients_database (dict): dictionary with patients and corresponding \n",
    "                                  images and records\n",
    "        path_to_copy (str): destination folder, where all dataset will\n",
    "                            be located\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create folder to the dataset\n",
    "    if not os.path.exists(path_to_copy):\n",
    "        os.mkdir(path_to_copy)\n",
    "    \n",
    "    for patient in tqdm(patients_database):\n",
    "        # Check wether patient's folder contains images\n",
    "        if len(patients_database[patient]) <=2:\n",
    "            continue\n",
    "        # Check wether patient contains the records\n",
    "        path_to_the_patient = patients_database[patient][0]\n",
    "\n",
    "        path_to_the_patient = '\\\\'.join(path_to_the_patient.split('\\\\')[:4])\n",
    "        if not check_wether_patient_has_records(path_to_the_patient):\n",
    "            continue\n",
    "\n",
    "        group_folder_name = patients_database[patient][0].split('\\\\')[0][2:]\n",
    "        group_folder_name = '_'.join([x.lower() for x in group_folder_name.split()])\n",
    "        \n",
    "#         patient_folder_name = patients_database[patient][0].split('\\\\')[1]\n",
    "        patient_folder_name = patient #'_'.join([x for x in patient_folder_name.split()])\n",
    "\n",
    "        # Create directories\n",
    "        if not os.path.exists(os.path.join(path_to_copy, group_folder_name)):\n",
    "            os.mkdir(os.path.join(path_to_copy, group_folder_name))\n",
    "        if not os.path.exists(os.path.join(path_to_copy, group_folder_name, patient_folder_name)):\n",
    "            os.mkdir(os.path.join(path_to_copy, group_folder_name, patient_folder_name))\n",
    "        \n",
    "        # Copy Records\n",
    "        shutil.copy(patients_database[patient][0], os.path.join(\n",
    "                path_to_copy, group_folder_name, patient_folder_name, patients_database[patient][0].split('\\\\')[-1]))\n",
    "        \n",
    "        # Create folder patients's for images\n",
    "        if not os.path.exists(os.path.join( path_to_copy, group_folder_name, patient_folder_name, 'images')):\n",
    "            os.mkdir(os.path.join( path_to_copy, group_folder_name, patient_folder_name, 'images'))\n",
    "            \n",
    "\n",
    "        # Copy images\n",
    "        for i in range(1, len(patients_database[patient])):\n",
    "            shutil.copy(patients_database[patient][i], os.path.join(\n",
    "                path_to_copy, patient_folder_name, 'images', patients_database[patient][i].split('\\\\')[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_THE_WHOLE_DATASET = 'D:\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_database = get_structure_of_the_dataset(PATH_TO_THE_WHOLE_DATASET)\n",
    "copy_dataset(patients_database, 'D:\\data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Take only MPRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'AW electronic film', 'Scout', 'Correction Halted 80% - Series 304 - adjust vessel tracking'\n",
    "\n",
    "'73','81', '71'\n",
    "\n",
    "'45%','42%','80%',\n",
    "\n",
    "'CTCA HD STD', 'CTCA','CTCA 73%','CTCA SMARTPHASE','CTCA 79%'\n",
    "\n",
    "'CALCIUM SCORE', 'CALCIUM SCORE C2'\n",
    "\n",
    "'SS-Freeze 39% - Original Series 306', 'Auto State - series 405 - 256 images','Auto State - series 301 - 256 images','Auto State - series 3 - 440 images', ,'Auto State - series 3 - 464 images', 'SS-Freeze 80% - Original Series 305','SS-Freeze 75% - Original Series 304','SS-Freeze 42% - Original Series 304','SS-Freeze 77% - Original Series 304','SS-Freeze 75% - Original Series 305','SS-Freeze 75% - Original Series 307','Auto State - series 405 - 256 images','SS-Freeze 39% - Original Series 306','SS-Freeze 39% - Original Series 306','SS-Freeze 77% - Original Series 305','SS-Freeze 81% - Original Series 305'\n",
    "\n",
    " '3D Saved State -  FINAL 76%'\n",
    " \n",
    " 'SVG-PDA graft'\n",
    " \n",
    " \n",
    " 'CALCIUM SCORE', 'CTCA', 'LAD *', 'LAD-D1 *', 'LAD-D2 *', 'OM *', 'PDA *', 'PLB *', 'PLB2 *', 'AW electronic film', 'Scout', 'LCX *', 'LCX-OM *', 'LAD-D3 *', 'LCX-OM2 *', 'PDA2 *', '73', 'RIB *', 'AM *', 'Correction Halted 80% - Series 304 - adjust vessel tracking', 'RCA *', 'RCA-AM *', 'PLB*', 'CTCA HD STD', '45%', 'RCA -PDA*', 'RCA -PLB*', 'RCA -AM*', 'OM2 *', 'RCA-PDA *', 'SS-Freeze 75% - Original Series 304', 'AM*', 'RIB-Branch of RIB *', 'LCX-OM1 *', 'CT ARTERIES', 'CTCA 73%', 'PLB1 *', '42%', 'SS-Freeze 42% - Original Series 304', 'SS-Freeze 77% - Original Series 304', 'LCX TO PDA *', 'LCX TO PDA2 *', 'LCX TO PLB *', 'AM1 *', 'AM2 *', '80%', 'LAD - D4 *', 'SS-Freeze 75% - Original Series 305', 'SS-Freeze 81% - Original Series 305', 'LCX-OM*', 'LCX-OM3 *', 'CALCIUM SCORE C2', '81', 'LCX - OM *', 'LCX - OM2 *', 'SS-Freeze 77% - Original Series 305', 'LAD', 'LAD-D1', 'LAD-D2', 'OM', 'OM2', 'RCA', 'PDA', 'SS-Freeze 75% - Original Series 307', 'RCA-PDA', 'RCA-PLB', 'OM1', 'OM3', 'RIB', 'CTCA SMARTPHASE', 'LCX', 'LCX-OM', 'PLB', 'LAD*', 'LAD-D1*', 'LCX TO PDA*', '71', 'OM3 *', 'PDA1 *', 'Branch 2 of PLB *', 'Branch of PLB *', 'LCX-OM2*', 'LCX-OM3*', 'RCA*', 'RCA-AM*', 'RCA-PDA*', 'RCA-PLB*', 'LAD-D2*', 'LCX*', 'LAD - D1', 'LCX-OM2', 'SS-Freeze 39% - Original Series 306', 'RCA-AM', 'RCA-PDA2', 'RCA-PLB2', 'RCA-PDA2*', 'Auto State - series 405 - 256 images', 'LCX-PLB', 'LCX-PDA', 'LAD-D3', 'LCX-OM1', 'LCX-OM3', 'LCX-PLB1', 'PDA2', '33', 'PLB2', 'PDA*', 'Auto State - series 3 - 256 images', 'CTCA 70%', 'Auto State - series 306 - 256 images', 'Auto State - series 301 - 256 images', '3D Saved State -  FINAL 76%', 'Auto State - series 304 - 256 images', 'LIMA-LAD', 'Aorta-D1', 'Aorta-D2', 'LAD original', 'LAD-D1 original', 'LCX original', 'LCX-OM original', 'PDA original', 'PDA2 original', 'PLB original', 'Aorta-LCX', 'Auto State - series 3 - 440 images', 'CTCA 79%', 'Auto State - series 305 - 256 images', 'Auto State - series 407 - 256 images', 'SS-Freeze 38% - Original Series 307', 'PLB1', 'LAD-D2 original', 'LAD-D3 original', 'OM original', 'RCA original', 'RCA-PDA original', 'RCA-PLB1 original', 'RCA-PLB2 original', 'LIMA-LAD graft', 'Aorta-LCX graft', 'Aorta-PDA graft', 'Auto State - series 3 - 464 images', 'Auto State - series 301 - 224 images', 'SS-Freeze 80% - Original Series 305', 'LAD-Branch of D1', 'LCX-Branch of OM', '59', 'Auto State - series 405 - 224 images', 'LCX-PDA2', 'RCA-AM1', 'RCA-AM2', 'OM4', 'LCX-PLB2', 'Auto State - series 304 - 224 images', 'LAD-D4', 'SS-Freeze 52% - Original Series 305', '70%', 'Auto State - series 304 - 376 images', 'SS-Freeze 78% - Original Series 305', 'RCA-PDA1', 'SS-Freeze 79% - Original Series 305', 'SS-Freeze 80% - Original Series 304', 'RCA-PLB1', 'Auto State - series 404 - 224 images', 'SS-Freeze 70% - Original Series 305', 'SS-Freeze 75% - Original Series 306', 'Auto State - series 406 - 224 images', 'Auto State - series 3 - 432 images', 'Auto State - series 403 - 256 images', 'SS-Freeze 75% - Original Series 303', 'LCX-OM4', 'RIB-Branch of RIB', 'Auto State - series 3 - 224 images', 'PDA1', 'OM-Branch of OM', 'SS-Freeze 74% - Original Series 305', 'LOCALISER', 'LAD Original', 'Auto State - series 3 - 456 images', 'LAD-D1 Original', 'Aorta-LAD graft', 'Aorta-D1 graft', 'SVG-PDA graft', 'SS-Freeze 45% - Original Series 306', 'Auto State - series 406 - 256 images', '80', 'SS-Freeze 45% - Original Series 310', 'Auto State - series 410 - 256 images', 'PDLB', 'SS-Freeze 33% - Original Series 305', 'SS-Freeze 50% - Original Series 305', '40', 'LCX-OM1*', 'SS-Freeze 51% - Original Series 308', 'SS-Freeze 72% - Original Series 309', 'RIB*', 'SS-Freeze 62% - Original Series 308', 'OM*', 'LAD-D3*', 'PDA2*', 'CALCIUM SCORE/70', 'SS-Freeze 70% - Original Series 306', 'LCX-PDA *', 'PLB2*', 'SS-Freeze 45% - Original Series 305', 'SS-Freeze 72% - Original Series 305', 'D1*', 'LCX-OM4 *', 'LCX-PLB *', 'RCA-PLB *', 'RCA-PDA1 *', 'RCA-PDA2 *', 'SS-Freeze 77% - Original Series 306', 'PLB3*', 'OM-Branch of OM *', '85', 'RCA-AM1 *', 'RCA-AM2 *', 'SS-Freeze 45% - Original Series 304', '43', 'LAD-Branch of D2 *', 'SS-Freeze 80% - Original Series 306', '75%', 'LAD TO PDA *', 'PDA TO LAD *', 'PDA3 *', 'RCA-PLB2 *', '28', 'AXIAL LUNG 2.5MM', '43%'\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " 'LCX-OM*', 'RCA-AM*', 'RCA-PDA*', 'RCA-PLB*', 'AW electronic film', 'Scout', 'CALCIUM SCORE', 'CTCA SMARTPHASE', 'LAD*', 'LAD-D1*', 'LAD-D2*', 'LCX*', 'LAD', 'LAD - D1', 'LCX', 'LCX-OM', 'LCX-OM2', 'RCA-PDA', 'RCA-PLB', 'LAD-D1', 'RIB', 'SS-Freeze 39% - Original Series 306', 'RCA-AM', 'LAD-D2', 'RCA-PDA2', 'RCA-PLB2', 'SS-Freeze 75% - Original Series 305', 'RCA-PDA2*', 'CTCA', 'Auto State - series 405 - 256 images', 'LCX-PLB', 'RCA', 'OM', 'LCX-PDA', 'LAD-D3', 'LCX-OM1', 'LCX-OM3', 'LCX-PLB1', 'PDA', 'PLB', 'PDA2', '33', 'PLB2', 'LCX-OM2*', 'LCX-OM3*', 'PDA*', 'PLB*', 'Auto State - series 3 - 256 images', 'CTCA 70%', 'Auto State - series 306 - 256 images', 'OM2', 'Auto State - series 301 - 256 images', '3D Saved State -  FINAL 76%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_mpr_names(path_to_dataset):\n",
    "    \"\"\"\n",
    "    Prints all unique mpr section names.\n",
    "    \"\"\"\n",
    "    folders = os.listdir(path_to_dataset)\n",
    "\n",
    "    unique_modalities = []\n",
    "    for folder_name in tqdm(folders):\n",
    "        for patient_name in tqdm(os.listdir(os.path.join(path_to_dataset))):\n",
    "            images = list(os.walk(os.path.join(path_to_dataset, patient_name, 'images')))[0][2]\n",
    "            \n",
    "            for image_name in images:\n",
    "                dicom_obj = pydicom.dcmread(os.path.join(path_to_dataset,patient_name, 'images', image_name))\n",
    "                if dicom_obj.SeriesDescription not in unique_modalities:\n",
    "                    unique_modalities.append(dicom_obj.SeriesDescription)\n",
    "#                     print(unique_modalities)     \n",
    "    print('       FINAL RESULTS:      ')\n",
    "    print(unique_modalities)\n",
    "    \n",
    "def copy_mpr_images_per_patient(path_to_dataset, path_to_save):\n",
    "    \"\"\"\n",
    "    Creates in path_to_save folder for each patient, where all MPR DICOM files are located.\n",
    "    \"\"\"\n",
    "    folders = os.listdir(path_to_dataset)\n",
    "    raw_images = ['CTCA', 'CALCIUM SCORE', 'Scout', 'AW electronic film', '40', '81', '85','Freeze','Auto State','33','3D']\n",
    "    for patient_name in tqdm(os.listdir(os.path.join(path_to_dataset))):\n",
    "        images = list(os.walk(os.path.join(path_to_dataset, patient_name, 'images')))[0][2]\n",
    "        if not os.path.exists(os.path.join(path_to_save,patient_name)):\n",
    "            os.mkdir(os.path.join(path_to_save,patient_name))\n",
    "        for image_name in images:\n",
    "            dicom_obj = pydicom.dcmread(os.path.join(path_to_dataset,patient_name, 'images', image_name))\n",
    "            if not any(sub_string in dicom_obj.SeriesDescription for sub_string in raw_images):\n",
    "                copyfile(os.path.join(path_to_dataset,patient_name, 'images', image_name),\n",
    "                         os.path.join(path_to_save,patient_name,image_name))\n",
    "# copy_mpr_images_per_patient(PATH_TO_DATA, 'lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'D:\\\\test\\without_viewer'\n",
    "PATH_TO_SAVE = r'D:\\test\\only_mprs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mpr_images_per_patient(PATH_TO_DATA, PATH_TO_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract PNG images from the MPRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mpr_name(mpr_name):\n",
    "    return \\\n",
    "        \"\".join(mpr_name.split()).replace('*', '').replace('original', '') \\\n",
    "        .replace('LIMA-', '').replace('Branchof','').replace('TOPDA', '').replace('PDATO', '')\n",
    "\n",
    "def get_patient_dictionary(path_to_patient_folder):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns dict of different types of images in the folder of patient. \n",
    "    \n",
    "    Returns:\n",
    "        dict: key - type of images; value - list of DICOM files, which sorted in the ascending order with restepct to the\n",
    "                    depth of the image slice.\n",
    "    \"\"\"\n",
    "    patient_dict = {}\n",
    "    \n",
    "    dicom_file_names = os.listdir(path_to_patient_folder)\n",
    "    \n",
    "    for i in range(len(dicom_file_names)):\n",
    "        cur_dicom_obj = dicom.dcmread(os.path.join(path_to_patient_folder, dicom_file_names[i]))\n",
    "        \n",
    "        if cur_dicom_obj.SeriesDescription not in patient_dict.keys():\n",
    "            patient_dict[cur_dicom_obj.SeriesDescription] = []\n",
    "        patient_dict[cur_dicom_obj.SeriesDescription].append(cur_dicom_obj)\n",
    "        \n",
    "    # sort each type of images with respect to their depth in ascending order\n",
    "    for i in patient_dict:\n",
    "        patient_dict[i].sort(key=lambda x: x.InstanceNumber)\n",
    "    \n",
    "    return patient_dict\n",
    "\n",
    "def get_pixels_hu(list_of_imgs):\n",
    "    \"\"\"\n",
    "    Convert stack of the images into Houndsfeld units\n",
    "    \"\"\"\n",
    "    image = np.stack([s.pixel_array for s in list_of_imgs])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = list_of_imgs[0].RescaleIntercept\n",
    "    slope = list_of_imgs[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_data = r'D:\\coronaryProject\\dataset\\binary_classification_MPR\\images'\n",
    "# path_to_new_data = r'E:\\ONLY_LAD\\\\'\n",
    "path_to_data = r'D:\\test\\only_mprs'\n",
    "path_to_new_data = r'D:\\test\\lad_png_images'\n",
    "list_of_patients = os.listdir(path_to_data)\n",
    "# patient_dictionary = get_patient_dictionary(path_to_data + '\\\\'+ list_of_patients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/27 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  4%|███                                                                                | 1/27 [00:06<02:47,  6.45s/it]\n",
      "\n",
      "\n",
      "  7%|██████▏                                                                            | 2/27 [00:19<03:32,  8.52s/it]\n",
      "\n",
      "\n",
      " 11%|█████████▏                                                                         | 3/27 [00:52<06:19, 15.80s/it]\n",
      "\n",
      "\n",
      " 15%|████████████▎                                                                      | 4/27 [01:18<07:12, 18.78s/it]\n",
      "\n",
      "\n",
      " 19%|███████████████▎                                                                   | 5/27 [01:49<08:13, 22.41s/it]\n",
      "\n",
      "\n",
      " 22%|██████████████████▍                                                                | 6/27 [02:27<09:32, 27.24s/it]\n",
      "\n",
      "\n",
      " 26%|█████████████████████▌                                                             | 7/27 [02:55<09:07, 27.38s/it]\n",
      "\n",
      "\n",
      " 30%|████████████████████████▌                                                          | 8/27 [03:19<08:22, 26.46s/it]\n",
      "\n",
      "\n",
      " 33%|███████████████████████████▋                                                       | 9/27 [03:45<07:53, 26.29s/it]\n",
      "\n",
      "\n",
      " 37%|██████████████████████████████▎                                                   | 10/27 [04:04<06:50, 24.12s/it]\n",
      "\n",
      "\n",
      " 41%|█████████████████████████████████▍                                                | 11/27 [04:20<05:48, 21.76s/it]\n",
      "\n",
      "\n",
      " 44%|████████████████████████████████████▍                                             | 12/27 [04:37<05:04, 20.27s/it]\n",
      "\n",
      "\n",
      " 48%|███████████████████████████████████████▍                                          | 13/27 [04:52<04:18, 18.49s/it]\n",
      "\n",
      "\n",
      " 52%|██████████████████████████████████████████▌                                       | 14/27 [05:18<04:31, 20.90s/it]\n",
      "\n",
      "\n",
      " 56%|█████████████████████████████████████████████▌                                    | 15/27 [05:47<04:38, 23.19s/it]\n",
      "\n",
      "\n",
      " 59%|████████████████████████████████████████████████▌                                 | 16/27 [06:13<04:25, 24.13s/it]\n",
      "\n",
      "\n",
      " 63%|███████████████████████████████████████████████████▋                              | 17/27 [06:42<04:15, 25.59s/it]\n",
      "\n",
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 18/27 [07:01<03:32, 23.57s/it]\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████████████████████████████████▋                        | 19/27 [07:27<03:15, 24.47s/it]\n",
      "\n",
      "\n",
      " 74%|████████████████████████████████████████████████████████████▋                     | 20/27 [07:55<02:58, 25.53s/it]\n",
      "\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 21/27 [08:22<02:34, 25.72s/it]\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████▊               | 22/27 [08:45<02:04, 24.97s/it]\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████████▊            | 23/27 [09:06<01:35, 23.75s/it]\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 24/27 [09:24<01:06, 22.08s/it]\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████████████████████████████████████████▉      | 25/27 [09:41<00:41, 20.52s/it]\n",
      "\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▉   | 26/27 [09:54<00:18, 18.44s/it]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [10:20<00:00, 20.68s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(list_of_patients))):\n",
    "    patient_dictionary = get_patient_dictionary(path_to_data + '\\\\'+ list_of_patients[i])\n",
    "    splited_mpr_names = [split_mpr_name(x) for x in patient_dictionary.keys()]\n",
    "    splited_mpr_names_filtered = [split_mpr_name(x).replace('LAD-', '').replace('D','D-').replace('AD-', 'AD') for x in patient_dictionary.keys() \n",
    "                                  if 'LAD' in split_mpr_name(x)]\n",
    "    dict_keys = list(patient_dictionary.keys())\n",
    "    \n",
    "    # change keys in the dict to the corresponding labels in the reports\n",
    "    for key_element in dict_keys:\n",
    "        patient_dictionary[split_mpr_name(key_element).replace('LAD-', '').replace('D','D-').replace('AD-', 'AD')] = \\\n",
    "            patient_dictionary[key_element]\n",
    "        del patient_dictionary[key_element]\n",
    "        \n",
    "    if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i])):\n",
    "        os.mkdir(os.path.join(path_to_new_data, list_of_patients[i]))\n",
    "\n",
    "    for key in patient_dictionary.keys():\n",
    "        if key not in splited_mpr_names_filtered:\n",
    "            continue\n",
    "        \n",
    "        for dicom_file in patient_dictionary[key]:\n",
    "            if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i])):\n",
    "                os.mkdir(os.path.join(path_to_new_data, list_of_patients[i]))\n",
    "            \n",
    "            if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i], key)):\n",
    "                os.mkdir(os.path.join(path_to_new_data, list_of_patients[i], key))\n",
    "#             dicom_file.save_as(os.path.join(path_to_new_data, \n",
    "#                                             list_of_patients[i], \n",
    "# #                                             key,\n",
    "# #                                             list_of_patients[i]+'_'+str(dicom_file.InstanceNumber)\n",
    "# #                                            )\n",
    "# #                               )\n",
    "            cv2.imwrite(os.path.join(path_to_new_data, \n",
    "                                            list_of_patients[i], \n",
    "                                            key,\n",
    "                                            list_of_patients[i]+'_'+str(dicom_file.InstanceNumber)+'.png'\n",
    "                                           ),\n",
    "                        cv2.normalize(dicom_file.pixel_array, None, alpha = 0, \n",
    "                                      beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "                       )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Copy reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_mpr_records(path_to_dataset, path_to_save):\n",
    "    \"\"\"\n",
    "    Copy all records from the dataset to path_to_save folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.mkdir(path_to_save)\n",
    "    folders = [x for x in os.listdir(path_to_dataset) if 'WITH RECONS ' in x]\n",
    "\n",
    "    for patient_name in os.listdir(os.path.join(path_to_dataset)):\n",
    "        files = os.listdir(os.path.join(path_to_dataset, patient_name))\n",
    "        files = [x for x in files if ('xlsx' in x) or ('doc' in x)]\n",
    "        files = files[0] if len(files)>0 else None\n",
    "        if files:\n",
    "            copyfile(os.path.join(path_to_dataset, patient_name, files), os.path.join(path_to_save, files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = r'd:\\test\\without_viewer'\n",
    "PATH_TO_SAVE = r'd:\\test\\records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mpr_records(PATH_TO_DATA, PATH_TO_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Merge Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_mpr_lad_name(mpr_name):\n",
    "    \"\"\"\n",
    "    Strip MPR name of the LAD artery. We do this step because the name in the doctor's report \n",
    "    is not equal to the name in the MPR. \n",
    "    \n",
    "    Returns:\n",
    "        - str: striped string\n",
    "    \"\"\"\n",
    "    return \"\".join(mpr_name.split()).replace('*', '').replace('original', '')\n",
    "\n",
    "def read_and_strip_record(path_to_record):\n",
    "    '''\n",
    "    Read record file and remove empty rows and rows with all NaNs.\n",
    "    \n",
    "    Returns:\n",
    "        - Pandas DataFrame: \n",
    "    '''\n",
    "    excel_file = pd.read_excel(path_to_record,index_col=None, header=None)\n",
    "    excel_file.dropna(how='all')\n",
    "    excel_file.rename(columns={0: 'a', 1: 'b'}, inplace=True)\n",
    "    excel_file = excel_file.fillna('  ')\n",
    "    excel_file = excel_file.replace('', '  ', regex=True)\n",
    "    excel_file = excel_file.drop(excel_file[excel_file['a'].str.isspace()].index)\n",
    "    return excel_file\n",
    "\n",
    "def get_lad_info_from_report(striped_record, artery_type):\n",
    "    \"\"\"\n",
    "    Takes striped(without any empty lines and NaNs) and returns info only about the certain artery type. \n",
    "    \n",
    "    Returns:\n",
    "        - list: each element is the string with some info about certain artery type\n",
    "    \"\"\"\n",
    "    lad_info = []\n",
    "    wether_add = False\n",
    "    lad_info.append(striped_record.iloc[0]['b'])\n",
    "    for ind, row_value in striped_record.iterrows():\n",
    "        \n",
    "        if wether_add and row_value['a'].isupper():\n",
    "            break\n",
    "        if wether_add:\n",
    "            lad_info.append(row_value['a'])\n",
    "        \n",
    "        if artery_type in row_value['a']:\n",
    "            wether_add = True\n",
    "    return lad_info\n",
    "\n",
    "def get_level_of_stenosis_from_string(artery_info):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        - list of str: each element is the string with percentage of stenosis. \n",
    "    \"\"\"\n",
    "    return [x.strip() for x in re.findall(r'.\\d{1,3}.?\\d{1,3}\\%', artery_info)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_records = r'd:\\test\\records'\n",
    "list_of_files = os.listdir(path_to_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/27 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      " 11%|█████████▏                                                                         | 3/27 [00:00<00:00, 25.22it/s]\n",
      "\n",
      "\n",
      " 22%|██████████████████▍                                                                | 6/27 [00:00<00:00, 24.07it/s]\n",
      "\n",
      "\n",
      " 33%|███████████████████████████▋                                                       | 9/27 [00:00<00:00, 24.35it/s]\n",
      "\n",
      "\n",
      " 44%|████████████████████████████████████▍                                             | 12/27 [00:00<00:00, 24.91it/s]\n",
      "\n",
      "\n",
      " 56%|█████████████████████████████████████████████▌                                    | 15/27 [00:00<00:00, 24.69it/s]\n",
      "\n",
      "\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 18/27 [00:00<00:00, 25.04it/s]\n",
      "\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 21/27 [00:00<00:00, 23.95it/s]\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 24/27 [00:00<00:00, 24.14it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:01<00:00, 23.70it/s]"
     ]
    }
   ],
   "source": [
    "extracted_lad_df = pd.DataFrame(columns=['PATIENT_ID','PROXIMAL', 'MID', 'DISTAL', 'D-1', 'D-2', 'D-3', 'D-4'])\n",
    "\n",
    "for i in tqdm(range(len(list_of_files))):\n",
    "    cur_file = read_and_strip_record(os.path.join(path_to_records, list_of_files[i]))\n",
    "    cur_patient_lad_info = get_lad_info_from_report(cur_file, 'LEFT ANTERIOR')\n",
    "    \n",
    "    new_row = pd.Series(#[Nan,Nan,Nan,Nan,Nan,Nan,Nan,Nan],\n",
    "                        ['-','-','-','-','-','-','-','-'],\n",
    "                        index=extracted_lad_df.columns)\n",
    "    new_row['PATIENT_ID'] = cur_patient_lad_info[0]\n",
    "    cur_patient_lad_info.pop(0)\n",
    "    list_of_lda_branches = list(extracted_lad_df.columns)\n",
    "    \n",
    "    for line_info in cur_patient_lad_info:\n",
    "        \n",
    "        artery_area_name = [x for x in list_of_lda_branches \n",
    "                            if x in line_info or x.lower() in line_info or x.title() in line_info]\n",
    "        if len(artery_area_name) >=1:\n",
    "            artery_area_name = artery_area_name[0]\n",
    "        else:\n",
    "            continue\n",
    "        stenosis_score = get_level_of_stenosis_from_string(line_info)\n",
    "        stenosis_score =  stenosis_score[0] if stenosis_score else 'NORMAL'\n",
    "        new_row.loc[artery_area_name] = stenosis_score\n",
    "    extracted_lad_df = extracted_lad_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>PROXIMAL</th>\n",
       "      <th>MID</th>\n",
       "      <th>DISTAL</th>\n",
       "      <th>D-1</th>\n",
       "      <th>D-2</th>\n",
       "      <th>D-3</th>\n",
       "      <th>D-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COV10031966</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTCAALC04021959</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>&lt;25%</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTCAALS24081961</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTCAARD10111950</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>&lt;25%</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTCABIB16101983</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PATIENT_ID PROXIMAL     MID  DISTAL     D-1     D-2 D-3 D-4\n",
       "0      COV10031966   NORMAL  NORMAL  NORMAL  NORMAL  NORMAL   -   -\n",
       "1  CTCAALC04021959   NORMAL    <25%  NORMAL  NORMAL  NORMAL   -   -\n",
       "2  CTCAALS24081961   NORMAL  NORMAL  NORMAL  NORMAL       -   -   -\n",
       "3  CTCAARD10111950   NORMAL    <25%  NORMAL  NORMAL  NORMAL   -   -\n",
       "4  CTCABIB16101983   NORMAL  NORMAL  NORMAL  NORMAL  NORMAL   -   -"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_lad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_lad_df.to_excel('lad_reports.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_patient(lad_segment, reports, patient_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "        get_label_for_patient('LAD', reports, 'DDJ261Z' )\n",
    "\n",
    "    \"\"\"\n",
    "    classes_to_positive = ['<25%','25%', 'NORMAL', '-']\n",
    "\n",
    "    if lad_segment == 'LAD':\n",
    "        curr_section_label = reports.loc[reports['PATIENT_ID'] == patient_id][['MID', 'PROXIMAL', 'DISTAL']].iloc[0]\n",
    "        stenosis_score = [x for x in curr_section_label if x not in classes_to_positive]\n",
    "        label = 1 if len(stenosis_score) > 0 else 0\n",
    "        return label, '___'.join(curr_section_label.values)\n",
    "        \n",
    "    else:\n",
    "        curr_section_label =  reports.loc[reports['PATIENT_ID'] == patient_id][lad_segment].iloc[0]\n",
    "        label = 0 if curr_section_label in classes_to_positive else 1    \n",
    "        return label, curr_section_label\n",
    "\n",
    "def get_labels(path_to_patient, reports):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        - dict: key(str) - type of the artery, value(int) - label(0 or 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    types_of_images = os.listdir(path_to_patient)\n",
    "    patient_name = [x for x in path_to_patient.split('/') if len(x) > 0][-1]\n",
    "    labels_dict = {}\n",
    "    \n",
    "    for i in range(len(types_of_images)):\n",
    "        labels_dict[types_of_images[i]] = get_label_for_patient(types_of_images[i], reports, patient_name)\n",
    "        \n",
    "    return labels_dict\n",
    "\n",
    "def get_imgs_names_to_the_labels(path_to_patient, labels_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - dict: key - branch of artery(str), value - label(int) 0 or 1.   \n",
    "    Returns:\n",
    "        - dict: key - label(int) 0 or 1, value(list) list of images, belong to the labelT\n",
    "    \"\"\"\n",
    "    img_labels = {}\n",
    "\n",
    "    for key in labels_dict.keys():\n",
    "        list_of_images = os.listdir(os.path.join(path_to_patient, key))\n",
    "        if labels_dict[key][1]=='-' or labels_dict[key][1]=='-___-___-':\n",
    "            continue\n",
    "        if labels_dict[key] in img_labels:\n",
    "            img_labels[labels_dict[key]]+= [x for x in list_of_images if '_text_deleted' in x]\n",
    "        else:\n",
    "            img_labels[labels_dict[key]] = [x for x in list_of_images if '_text_deleted' in x]\n",
    "            \n",
    "    return img_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
