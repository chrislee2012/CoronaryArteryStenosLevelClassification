{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#pytorch packages\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#To download the dataset for torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import time\n",
    "from ast import literal_eval\n",
    "from datasets.mpr_dataset import MPR_Dataset, MPR_Dataset_STENOSIS_REMOVAL, MPR_Dataset_LSTM, MPR_Dataset_LSTM_H5, MPR_Dataset_H5\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import yaml\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will try to recognize hand-written digits, specifically the ones of the MNIST dataset, that contains overall 70,000 28-by-28-pixels pictures of hand-written digits. This dataset is easily accessible in pytorch via dataset.MNSIT. You just have to specify you want to download it if it's not already in the directory, and pytorch will process it to create a DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to the directory of your choice.\n",
    "root_dir = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches_with_pda_plv_h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "   config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "import inspect\n",
    "import importlib\n",
    "\n",
    "def __module_mapping(module_name):\n",
    "    mapping = {}\n",
    "    for name, obj in inspect.getmembers(importlib.import_module(module_name), inspect.isclass):\n",
    "        mapping[name] = obj\n",
    "    return mapping\n",
    "\n",
    "def __load_augmentation(config):\n",
    "    if 'augmentation' in config['data']:\n",
    "        mapping = __module_mapping('augmentations')\n",
    "        augmentation = mapping[config['data']['augmentation']['name']](\n",
    "            **config['data']['augmentation']['parameters'])\n",
    "    else:\n",
    "        augmentation = None\n",
    "    return augmentation\n",
    "\n",
    "def __load_sampler(sampler_name):\n",
    "    mapping = __module_mapping('samplers')\n",
    "    sampler = mapping[sampler_name]\n",
    "    return sampler\n",
    "\n",
    "def __load_model(config):\n",
    "    mapping = __module_mapping('models')\n",
    "    if 'parameters' not in config['model']:\n",
    "        config['model']['parameters'] = {}\n",
    "    \n",
    "    n_class = len(config['data']['groups'])\n",
    "    config['model']['parameters']['n_classes'] = n_class\n",
    "    model = mapping[config['model']['name']](config['model']['parameters'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "augmentation = __load_augmentation(config)\n",
    "sampler= __load_sampler('ImbalancedDatasetSampler') \n",
    "dataset = MPR_Dataset_H5(root_dir, config=config[\"data\"], augmentation=augmentation, transform=transform)\n",
    "\n",
    "# print(np.unique(np.array(dataset.labels), return_counts=True))\n",
    "trn_set = MPR_Dataset_H5(root_dir, partition=\"train\", config=config[\"data\"], transform=transform,\n",
    "                                    augmentation=augmentation)\n",
    "tst_set = MPR_Dataset_H5(root_dir, partition=\"test\", config=config[\"data\"], transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data in the training set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87551, 13122)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set), len(tst_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented by a tensor of size 28 by 28, each value represents the color of the corresponding pixel, from 0 (black) to 255 (white). Torch tensors are the equivalent of numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to convert a torch tensor to a numpy array via the .numpy() command.\n",
    "\n",
    "Conversely, you can create a torch Tensor from a numpy array x via torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set[0][0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then easy to see the corresponding picture via plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(trn_set[0][0].numpy()[0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the corresponding label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pytorch neural network will expect the data to come in the form of minibatches of tensors. To do that, we use a pytorch object called DataLoader. It will randomly separate the pictures (with the associated label) in minibatches. If you have multiple GPUs, it also prepares the work to be parallelized between them (just change num_workers from 0 to your custom value). We only shuffle the data randomly for the training.\n",
    "\n",
    "First we need to explicitely ask our dataset to transform the images in tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = DataLoader(trn_set, sampler=sampler(trn_set),\n",
    "                                       batch_size=config[\"dataloader\"][\"batch_size\"])\n",
    "tst_loader = DataLoader(tst_set, shuffle=False, batch_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example. A data loader can be converted into an iterator and we can then ask him for a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a minibacth containts two torch tensors: the first one contains the data (here our pictures) and the second one the expected labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example[0].size(), mb_example[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch has automatically added one dimension to our images (the 1 in second position). It would be 3 if we had had the three usual channels for the colors (RGB). Pytorch puts this channel in the second dimension and not the last because it simplifies some computation.\n",
    "\n",
    "Let's see the first tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example[0][0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pytorch transformed the values that went from 0 to 255 into floats that go from 0. to 1.\n",
    "\n",
    "We can have a look at the first pictures and draw them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# for i in range(0,4):\n",
    "#     sub_plot = fig.add_subplot(1,4,i+1)\n",
    "#     sub_plot.axis('Off')\n",
    "#     plt.imshow(mb_example[0][i,0].numpy(), cmap='Greys')\n",
    "#     sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another usual transformation we do before feeing the pictures to our neural network is to normalize the input. This means subtracting the mean and dividing by the standard deviation. We can either search for the usual values on Google or compute them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = torch.mean(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "# std = torch.std(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "# mean,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide by 255 to get the means of our data when it's convereted into floats from 0. to 1.\n",
    "\n",
    "Then we go back to creating a transfrom and add the normalization. Note that we use the same mean and std for the test set. Afterward, we reload our datasets, adding this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
    "# trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "# tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "# tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to plot our digits, we will have to denormalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# for i in range(0,4):\n",
    "#     sub_plot = fig.add_subplot(1,4,i+1)\n",
    "#     sub_plot.axis('Off')\n",
    "#     plt.imshow(mb_example[0][i,0].numpy() * std + mean, cmap='Greys', interpolation=None)\n",
    "#     sub_plot.set_title(mb_example[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always a good idea to create a model as a subclass of nn.Module. That way, we can use all the features this class provides.\n",
    "\n",
    "We override the init function (but still call the init function of nn.Module) to define our custom layers (here two linear layers) and we have to define the forward function, which explains how to compute the output.\n",
    "\n",
    "The first line of the forward function is to flatten our input, since we saw it has four dimensions: minibatch by channel by height by width. We only keep the minibatch size as our first dimension (x.size(0)) and the -1 is to tell pytorch to determine the right number for the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_model(config):\n",
    "    mapping = __module_mapping('models')\n",
    "    if 'parameters' not in config['model']:\n",
    "        config['model']['parameters'] = {}\n",
    "    \n",
    "    n_class = len(config['data']['groups'])\n",
    "    config['model']['parameters']['n_classes'] = n_class\n",
    "    model = mapping[config['model']['name']](**config['model']['parameters'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleNeuralNet(nn.Module):\n",
    "#     def __init__(self, n_in, n_hidden, n_out):\n",
    "#         super().__init__()\n",
    "#         self.linear1 = nn.Linear(n_in, n_hidden)\n",
    "#         self.linear2 = nn.Linear(n_hidden, n_out)\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         x = x.view(x.size(0),-1)\n",
    "#         x = F.relu(self.linear1(x))\n",
    "#         return F.log_softmax(self.linear2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can instanciate the class with our input size (28 * 28), an hidden size of 100 layers and 10 outputs (as many as digits).\n",
    "\n",
    "The optimizer will automatically do the Stochastic Gradient Descent for us (or any of its variant if we want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = __load_model(config)\n",
    "net = net.cuda()\n",
    "optimizer = optim.Adam(net.parameters(),lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to write our training loop. To compute the gradient automatically, pytorch requires us to put the torch tensors with our inputs and labels into Variable objects, that way it'll remember the transformation these go through until we arrive at our loss function. We then call loss.backward() to compute all the gradients (which will then be in the grad field of any variable).\n",
    "\n",
    "The optimizer takes care of the step of our gradient descent in the optimizer.step() function. Since the gradients are accumulated, we have to tell pytorch when to reinitialize them (which the purpose of the optimizer.zero_grad() command at the beginning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print('Epoch {}:'.format(epoch+1))\n",
    "        for data in tqdm(trn_loader):\n",
    "            #separate the inputs from the labels\n",
    "            inputs,labels = data\n",
    "            inputs,labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            #Compute the outputs given by our model at this stage.\n",
    "            outputs = net(inputs)\n",
    "            outputs =  F.log_softmax(outputs, dim=-1)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            #Compute the loss\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds)\n",
    "            #Backpropagate the computation of the gradients\n",
    "            loss.backward()\n",
    "            #Do the step of the SGD\n",
    "            optimizer.step()\n",
    "            break\n",
    "        print('Loss: {}  Accuracy: {}'.format(running_loss/len(trn_set), (100.*corrects/len(trn_set)) / 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcbba98b5204e85af1aaaf71e53869f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.0008032669001328958  Accuracy: 0\n",
      "Epoch 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120beebcebf14b95881658677161bb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.000803481705874915  Accuracy: 0\n",
      "Epoch 3:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1274fb1ef2414e9e1cee5cdd64dd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.0008044621437667849  Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "train(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96.3% accuracy is good, but that's on the training set and we may be overfitting. Let's try on the test set now to see if we're doing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tqdm(tst_loader):\n",
    "        #separate the inputs from the labels\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.cuda(), labels.cuda()\n",
    "        #Even if we don't require the gradient here, a nn.Module expects a variable.\n",
    "        #Compute the outputs given by our model at this stage.\n",
    "        outputs = net(inputs)\n",
    "        outputs =  F.log_softmax(outputs, dim=-1)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        #Compute the loss\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds)\n",
    "    print('Loss: {}  Accuracy: {}'.format(running_loss/len(trn_set), (100.*corrects/len(trn_set)) / 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we weren't overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of how this code has been built are all explained in this [blog article](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(trn_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in tqdm(trn_loader):\n",
    "        batch_num += 1\n",
    "        #As before, get the loss for this mini-batch of inputs/outputs\n",
    "        inputs,labels = data\n",
    "        inputs,labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        outputs =  F.log_softmax(outputs, dim=-1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        #Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    return log_lrs, losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our neural net as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = __load_model(config)\n",
    "net = net.cuda()\n",
    "optimizer = optim.Adam(net.parameters(),lr=1e-1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the losses versus the logs of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cbe710aaf14ac6be93ca85901e2209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logs,losses = find_lr(init_value = 1e-8, final_value=10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feccde47160>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logs[10:-5],losses[10:-5])\n",
    "plt.v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 ** (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[10:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests the best learning rate is $10^{-1}$ so we can use test this one after defining a new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = __load_model(config)\n",
    "net = net.cuda()\n",
    "optimizer = optim.SGD(net.parameters(),lr=10 ** (-0.5))\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already at 92.21% accuracy when the learning rate used before gave us 84.86% in one epoch!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
