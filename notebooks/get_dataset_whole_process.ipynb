{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "import pydicom as dicom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "# from __future__ import print_function\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from numpy import nan as Nan\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Copy data without DICOM viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wether_patient_has_records(path_to_patient_folder, get_names_of_records=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        get_names_of_records (bool): wether return names of record files\n",
    "        \n",
    "    Returns:\n",
    "        bool: Retuns value. True if patient folder contains the records and False otherwise. \n",
    "        or\n",
    "        tuple (bool, list): returns bool and names of the record files for the patient.  \n",
    "    \"\"\"\n",
    "    names_of_the_records = [x for x in os.listdir(path_to_patient_folder) if 'doc' in x or 'xlsx' in x]\n",
    "    if get_names_of_records:\n",
    "        return len(names_of_the_records) >=1, names_of_the_records\n",
    "    else:\n",
    "        return len(names_of_the_records) >=1\n",
    "\n",
    "def check_wether_patient_has_image_data(path_to_patient_folder):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        bool : Returns True if patient folder contatin image data and False otherwise\n",
    "    \"\"\"\n",
    "    names_of_the_records = [x for x in os.listdir(path_to_patient_folder) if 'DICOMOBJ' in x]\n",
    "    return len(names_of_the_records) >= 1\n",
    "\n",
    "def get_structure_of_the_dataset(path_to_dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns:\n",
    "        dict :  keys - patient names(str): values (list of strings) - paths to the images and records\n",
    "                                                    \n",
    "    \"\"\"\n",
    "    patients_database = {}\n",
    "    \n",
    "    reports_folders = [x for x in os.listdir(path_to_dataset) if not any(i in x for i in\n",
    "                            ['System', 'BIN', '$.BIN', 'Autorun.inf','Seagate', 'SeagateExpansion.ico', \n",
    "                             'Start_Here_Mac.app', 'Start_Here_Win.exe', 'Warranty.pdf'])]\n",
    "                       #'System' not in x and 'BIN' not in x]\n",
    "    for report_folder in tqdm(reports_folders):\n",
    "        patients_per_folder = os.listdir(os.path.join(path_to_dataset, report_folder))\n",
    "        \n",
    "        for patient in patients_per_folder:\n",
    "            \n",
    "            files_in_patient_folder = os.listdir(os.path.join(path_to_dataset, report_folder, patient))\n",
    "            \n",
    "            if check_wether_patient_has_image_data(os.path.join(path_to_dataset, report_folder, patient)):\n",
    "                patient_images = os.listdir(os.path.join(path_to_dataset, report_folder, patient, 'DICOMOBJ'))\n",
    "                patient_images_paths = [os.path.join(path_to_dataset, report_folder, patient, 'DICOMOBJ', x) \n",
    "                                 for x in patient_images]\n",
    "            else:\n",
    "                patient_images = []\n",
    "                patient_images_paths = []\n",
    "            _, patient_records = check_wether_patient_has_records(\n",
    "                                      os.path.join(path_to_dataset, report_folder, patient), \n",
    "                                      get_names_of_records=True)\n",
    "            patient_records_paths = [os.path.join(path_to_dataset, report_folder, patient, x) for x in patient_records]\n",
    "            patients_database[patient] = []\n",
    "            patients_database[patient] += patient_records_paths\n",
    "            patients_database[patient] += patient_images_paths\n",
    "    \n",
    "    return patients_database\n",
    "\n",
    "def copy_dataset(patients_database, path_to_copy):\n",
    "    \"\"\"\n",
    "    Copy only image data and records without DICOM viewer program\n",
    "    Args:\n",
    "        patients_database (dict): dictionary with patients and corresponding \n",
    "                                  images and records\n",
    "        path_to_copy (str): destination folder, where all dataset will\n",
    "                            be located\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create folder to the dataset\n",
    "    if not os.path.exists(path_to_copy):\n",
    "        os.mkdir(path_to_copy)\n",
    "    \n",
    "    for patient in tqdm(patients_database):\n",
    "        # Check wether patient's folder contains images\n",
    "        if len(patients_database[patient]) <=2:\n",
    "            continue\n",
    "        # Check wether patient contains the records\n",
    "        path_to_the_patient = patients_database[patient][0]\n",
    "\n",
    "        path_to_the_patient = '\\\\'.join(path_to_the_patient.split('\\\\')[:4])\n",
    "        if not check_wether_patient_has_records(path_to_the_patient):\n",
    "            continue\n",
    "\n",
    "        group_folder_name = patients_database[patient][0].split('\\\\')[0][2:]\n",
    "        group_folder_name = '_'.join([x.lower() for x in group_folder_name.split()])\n",
    "        \n",
    "#         patient_folder_name = patients_database[patient][0].split('\\\\')[1]\n",
    "        patient_folder_name = patient #'_'.join([x for x in patient_folder_name.split()])\n",
    "\n",
    "        # Create directories\n",
    "        if not os.path.exists(os.path.join(path_to_copy, group_folder_name)):\n",
    "            os.mkdir(os.path.join(path_to_copy, group_folder_name))\n",
    "        if not os.path.exists(os.path.join(path_to_copy, group_folder_name, patient_folder_name)):\n",
    "            os.mkdir(os.path.join(path_to_copy, group_folder_name, patient_folder_name))\n",
    "        \n",
    "        # Copy Records\n",
    "        shutil.copy(patients_database[patient][0], os.path.join(\n",
    "                path_to_copy, group_folder_name, patient_folder_name, patients_database[patient][0].split('\\\\')[-1]))\n",
    "        \n",
    "        # Create folder patients's for images\n",
    "        if not os.path.exists(os.path.join( path_to_copy, group_folder_name, patient_folder_name, 'images')):\n",
    "            os.mkdir(os.path.join( path_to_copy, group_folder_name, patient_folder_name, 'images'))\n",
    "            \n",
    "\n",
    "        # Copy images\n",
    "        for i in range(1, len(patients_database[patient])):\n",
    "            shutil.copy(patients_database[patient][i], os.path.join(\n",
    "                path_to_copy, patient_folder_name, 'images', patients_database[patient][i].split('\\\\')[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_THE_WHOLE_DATASET = 'D:\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_database = get_structure_of_the_dataset(PATH_TO_THE_WHOLE_DATASET)\n",
    "copy_dataset(patients_database, 'D:\\data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Take only MPRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'AW electronic film', 'Scout', 'Correction Halted 80% - Series 304 - adjust vessel tracking'\n",
    "\n",
    "'73','81', '71'\n",
    "\n",
    "'45%','42%','80%',\n",
    "\n",
    "'CTCA HD STD', 'CTCA','CTCA 73%','CTCA SMARTPHASE','CTCA 79%'\n",
    "\n",
    "'CALCIUM SCORE', 'CALCIUM SCORE C2'\n",
    "\n",
    "'SS-Freeze 39% - Original Series 306', 'Auto State - series 405 - 256 images','Auto State - series 301 - 256 images','Auto State - series 3 - 440 images', ,'Auto State - series 3 - 464 images', 'SS-Freeze 80% - Original Series 305','SS-Freeze 75% - Original Series 304','SS-Freeze 42% - Original Series 304','SS-Freeze 77% - Original Series 304','SS-Freeze 75% - Original Series 305','SS-Freeze 75% - Original Series 307','Auto State - series 405 - 256 images','SS-Freeze 39% - Original Series 306','SS-Freeze 39% - Original Series 306','SS-Freeze 77% - Original Series 305','SS-Freeze 81% - Original Series 305'\n",
    "\n",
    " '3D Saved State -  FINAL 76%'\n",
    " \n",
    " 'SVG-PDA graft'\n",
    " \n",
    " \n",
    " 'CALCIUM SCORE', 'CTCA', 'LAD *', 'LAD-D1 *', 'LAD-D2 *', 'OM *', 'PDA *', 'PLB *', 'PLB2 *', 'AW electronic film', 'Scout', 'LCX *', 'LCX-OM *', 'LAD-D3 *', 'LCX-OM2 *', 'PDA2 *', '73', 'RIB *', 'AM *', 'Correction Halted 80% - Series 304 - adjust vessel tracking', 'RCA *', 'RCA-AM *', 'PLB*', 'CTCA HD STD', '45%', 'RCA -PDA*', 'RCA -PLB*', 'RCA -AM*', 'OM2 *', 'RCA-PDA *', 'SS-Freeze 75% - Original Series 304', 'AM*', 'RIB-Branch of RIB *', 'LCX-OM1 *', 'CT ARTERIES', 'CTCA 73%', 'PLB1 *', '42%', 'SS-Freeze 42% - Original Series 304', 'SS-Freeze 77% - Original Series 304', 'LCX TO PDA *', 'LCX TO PDA2 *', 'LCX TO PLB *', 'AM1 *', 'AM2 *', '80%', 'LAD - D4 *', 'SS-Freeze 75% - Original Series 305', 'SS-Freeze 81% - Original Series 305', 'LCX-OM*', 'LCX-OM3 *', 'CALCIUM SCORE C2', '81', 'LCX - OM *', 'LCX - OM2 *', 'SS-Freeze 77% - Original Series 305', 'LAD', 'LAD-D1', 'LAD-D2', 'OM', 'OM2', 'RCA', 'PDA', 'SS-Freeze 75% - Original Series 307', 'RCA-PDA', 'RCA-PLB', 'OM1', 'OM3', 'RIB', 'CTCA SMARTPHASE', 'LCX', 'LCX-OM', 'PLB', 'LAD*', 'LAD-D1*', 'LCX TO PDA*', '71', 'OM3 *', 'PDA1 *', 'Branch 2 of PLB *', 'Branch of PLB *', 'LCX-OM2*', 'LCX-OM3*', 'RCA*', 'RCA-AM*', 'RCA-PDA*', 'RCA-PLB*', 'LAD-D2*', 'LCX*', 'LAD - D1', 'LCX-OM2', 'SS-Freeze 39% - Original Series 306', 'RCA-AM', 'RCA-PDA2', 'RCA-PLB2', 'RCA-PDA2*', 'Auto State - series 405 - 256 images', 'LCX-PLB', 'LCX-PDA', 'LAD-D3', 'LCX-OM1', 'LCX-OM3', 'LCX-PLB1', 'PDA2', '33', 'PLB2', 'PDA*', 'Auto State - series 3 - 256 images', 'CTCA 70%', 'Auto State - series 306 - 256 images', 'Auto State - series 301 - 256 images', '3D Saved State -  FINAL 76%', 'Auto State - series 304 - 256 images', 'LIMA-LAD', 'Aorta-D1', 'Aorta-D2', 'LAD original', 'LAD-D1 original', 'LCX original', 'LCX-OM original', 'PDA original', 'PDA2 original', 'PLB original', 'Aorta-LCX', 'Auto State - series 3 - 440 images', 'CTCA 79%', 'Auto State - series 305 - 256 images', 'Auto State - series 407 - 256 images', 'SS-Freeze 38% - Original Series 307', 'PLB1', 'LAD-D2 original', 'LAD-D3 original', 'OM original', 'RCA original', 'RCA-PDA original', 'RCA-PLB1 original', 'RCA-PLB2 original', 'LIMA-LAD graft', 'Aorta-LCX graft', 'Aorta-PDA graft', 'Auto State - series 3 - 464 images', 'Auto State - series 301 - 224 images', 'SS-Freeze 80% - Original Series 305', 'LAD-Branch of D1', 'LCX-Branch of OM', '59', 'Auto State - series 405 - 224 images', 'LCX-PDA2', 'RCA-AM1', 'RCA-AM2', 'OM4', 'LCX-PLB2', 'Auto State - series 304 - 224 images', 'LAD-D4', 'SS-Freeze 52% - Original Series 305', '70%', 'Auto State - series 304 - 376 images', 'SS-Freeze 78% - Original Series 305', 'RCA-PDA1', 'SS-Freeze 79% - Original Series 305', 'SS-Freeze 80% - Original Series 304', 'RCA-PLB1', 'Auto State - series 404 - 224 images', 'SS-Freeze 70% - Original Series 305', 'SS-Freeze 75% - Original Series 306', 'Auto State - series 406 - 224 images', 'Auto State - series 3 - 432 images', 'Auto State - series 403 - 256 images', 'SS-Freeze 75% - Original Series 303', 'LCX-OM4', 'RIB-Branch of RIB', 'Auto State - series 3 - 224 images', 'PDA1', 'OM-Branch of OM', 'SS-Freeze 74% - Original Series 305', 'LOCALISER', 'LAD Original', 'Auto State - series 3 - 456 images', 'LAD-D1 Original', 'Aorta-LAD graft', 'Aorta-D1 graft', 'SVG-PDA graft', 'SS-Freeze 45% - Original Series 306', 'Auto State - series 406 - 256 images', '80', 'SS-Freeze 45% - Original Series 310', 'Auto State - series 410 - 256 images', 'PDLB', 'SS-Freeze 33% - Original Series 305', 'SS-Freeze 50% - Original Series 305', '40', 'LCX-OM1*', 'SS-Freeze 51% - Original Series 308', 'SS-Freeze 72% - Original Series 309', 'RIB*', 'SS-Freeze 62% - Original Series 308', 'OM*', 'LAD-D3*', 'PDA2*', 'CALCIUM SCORE/70', 'SS-Freeze 70% - Original Series 306', 'LCX-PDA *', 'PLB2*', 'SS-Freeze 45% - Original Series 305', 'SS-Freeze 72% - Original Series 305', 'D1*', 'LCX-OM4 *', 'LCX-PLB *', 'RCA-PLB *', 'RCA-PDA1 *', 'RCA-PDA2 *', 'SS-Freeze 77% - Original Series 306', 'PLB3*', 'OM-Branch of OM *', '85', 'RCA-AM1 *', 'RCA-AM2 *', 'SS-Freeze 45% - Original Series 304', '43', 'LAD-Branch of D2 *', 'SS-Freeze 80% - Original Series 306', '75%', 'LAD TO PDA *', 'PDA TO LAD *', 'PDA3 *', 'RCA-PLB2 *', '28', 'AXIAL LUNG 2.5MM', '43%'\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " 'LCX-OM*', 'RCA-AM*', 'RCA-PDA*', 'RCA-PLB*', 'AW electronic film', 'Scout', 'CALCIUM SCORE', 'CTCA SMARTPHASE', 'LAD*', 'LAD-D1*', 'LAD-D2*', 'LCX*', 'LAD', 'LAD - D1', 'LCX', 'LCX-OM', 'LCX-OM2', 'RCA-PDA', 'RCA-PLB', 'LAD-D1', 'RIB', 'SS-Freeze 39% - Original Series 306', 'RCA-AM', 'LAD-D2', 'RCA-PDA2', 'RCA-PLB2', 'SS-Freeze 75% - Original Series 305', 'RCA-PDA2*', 'CTCA', 'Auto State - series 405 - 256 images', 'LCX-PLB', 'RCA', 'OM', 'LCX-PDA', 'LAD-D3', 'LCX-OM1', 'LCX-OM3', 'LCX-PLB1', 'PDA', 'PLB', 'PDA2', '33', 'PLB2', 'LCX-OM2*', 'LCX-OM3*', 'PDA*', 'PLB*', 'Auto State - series 3 - 256 images', 'CTCA 70%', 'Auto State - series 306 - 256 images', 'OM2', 'Auto State - series 301 - 256 images', '3D Saved State -  FINAL 76%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_unique_mpr_names(path_to_dataset):\n",
    "    \"\"\"\n",
    "    Prints all unique mpr section names.\n",
    "    \"\"\"\n",
    "    folders = os.listdir(path_to_dataset)\n",
    "    \n",
    "    lol = ['78SSF', 'LOCALISER', 'Lt Septal Branch ', 'CT ARTERIES', 'Conus Artery *', 'AXIAL LUNG 2.5MM', \n",
    "           'LIMA-LAD graft', 'Aorta-LAD graft', 'RT Anomaly *', 'AXIAL MEDIASTINUM 2.5MM', 'Localiser', 'LIMA-LAD graft', \n",
    "           'SScoreSerSav', 'PatientReport', 'ECG Report', 'Dose Report', 'ScreenSave']\n",
    "    thrash = 0\n",
    "    lol2 = ['OM-Branch of OM *', 'LCX-Branch of OM *', 'RIB-Branch of RIB *', 'Branch of PLB *', 'Branch 2 of PLB *', \n",
    "            'OM-Branch of OM', 'LCX-Branch of OM', 'RIB-Branch of RIB', 'OM-Branch OM *', 'LAD-Branch of D1',\n",
    "            'LCX-Branch of OM1 *', '81SSF', 'PLB3 *', 'LAD-Branch of D2 *', 'Branch of AM *']\n",
    "    branch=0\n",
    "    lol3 = ['Aorta-D1', 'Aorta-LCX', 'Aorta-D2', 'Aorta-OM graft*', 'Aorta-PDA graft *', 'Aorta-D1 graft *', \n",
    "            'Aorta-OM graft *','Aorta-LCX graft', 'Aorta-PDA graft', 'Aorta-D1 graft']\n",
    "    aorta=0\n",
    "    unique_modalities = []\n",
    "    for patient_name in tqdm(os.listdir(os.path.join(path_to_dataset))):\n",
    "        images = list(os.walk(os.path.join(path_to_dataset, patient_name)))[0][2]\n",
    "\n",
    "        for image_name in images:\n",
    "            dicom_obj = pydicom.dcmread(os.path.join(path_to_dataset,patient_name, image_name))\n",
    "            \n",
    "            if dicom_obj.SeriesDescription in lol:\n",
    "                thrash+=1\n",
    "            elif dicom_obj.SeriesDescription in lol2:\n",
    "                branch+=1\n",
    "            elif dicom_obj.SeriesDescription in lol3:\n",
    "                aorta+=1\n",
    "            \n",
    "            if dicom_obj.SeriesDescription not in unique_modalities:\n",
    "                unique_modalities.append(dicom_obj.SeriesDescription)\n",
    "                \n",
    "    return thrash, branch,aorta\n",
    "#                     print(unique_modalities)     \n",
    "#     print('       FINAL RESULTS:      ')\n",
    "#     print(unique_modalities)\n",
    "    \n",
    "def copy_mpr_images_per_patient(path_to_dataset, path_to_save):\n",
    "    \"\"\"\n",
    "    Creates in path_to_save folder for each patient, where all MPR DICOM files are located.\n",
    "    \"\"\"\n",
    "    folders = os.listdir(path_to_dataset)\n",
    "    raw_images = ['CTCA', 'CALCIUM SCORE', 'Scout', 'AW electronic film', '40', '81', '85','Freeze','Auto State','33','3D']\n",
    "    for patient_name in tqdm(os.listdir(os.path.join(path_to_dataset))):\n",
    "        images = list(os.walk(os.path.join(path_to_dataset, patient_name, 'images')))[0][2]\n",
    "        if not os.path.exists(os.path.join(path_to_save,patient_name)):\n",
    "            os.mkdir(os.path.join(path_to_save,patient_name))\n",
    "        for image_name in images:\n",
    "            dicom_obj = pydicom.dcmread(os.path.join(path_to_dataset,patient_name, 'images', image_name))\n",
    "            if not any(sub_string in dicom_obj.SeriesDescription for sub_string in raw_images):\n",
    "                copyfile(os.path.join(path_to_dataset,patient_name, 'images', image_name),\n",
    "                         os.path.join(path_to_save,patient_name,image_name))\n",
    "# copy_mpr_images_per_patient(PATH_TO_DATA, 'lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/ONLY_MPR'\n",
    "PATH_TO_SAVE = r'D:\\test\\only_mprs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrash, branch,aorta = get_unique_mpr_names(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrash, branch, aorta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mpr_images_per_patient(PATH_TO_DATA, PATH_TO_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All unique values\n",
    "'LAD-D2',  'LAD-D1', 'LAD', 'LAD *', 'LAD-D1 *', 'LAD-D2 *', , 'LAD-D3 *', 'LIMA-LAD', 'LAD-D1 original', 'LAD original', 'LAD*', 'LAD-D1*', 'LAD-D3', 'LAD-D2*', 'LAD-D3*', 'LAD - D4 *', 'LAD-D4', 'LAD TO PDA *', '2LAD-D2', 'LAD -D1*', 'LAD -D2*', 'LAD-D3 original', 'LAD-D2 original',  'LAD -D1', 'LAD -D2', 'LAD-D1 Original', 'LAD Original', 'LAD-D4 *', 'D1*', 'LAD - D1'\n",
    "\n",
    "\n",
    "\n",
    "'RCA', 'RCA-PDA', 'PDA *', 'PDA2 original', 'PDA original', 'PDA2 *','RCA-AM *', 'RCA *', 'RCA-AM1', 'PDA', 'PDA1 *','PDA*','PDA3 *', 'PDA2','RCA*', 'PDA2*',  'PDA1*', 'PDA1', 'PDA 2*','PDA-AM *', 'RCA -PDA*'\n",
    "\n",
    "'RCA-AM',\n",
    "\n",
    "'RCA-PLB', 'RCA-PLB *', 'RCA-PLB*', 'RCA -PLB*', 'RCA-PLB1', 'RCA-PLB1 *', 'RCA-PLB2', 'RCA-PLB2 *',\n",
    "\n",
    "'RCA-PDA*', 'RCA-PDA *', 'RCA-PDA1', 'RCA-PLB1 *', 'RCA-PDA2', 'RCA-PDA2 *'\n",
    "\n",
    "'RCA -AM*', 'RCA-AM*', 'RCA-AM2 *', 'RCA-AM1 *', 'PDA TO LAD *', 'PDA2  *', \n",
    "\n",
    "'RCA-PLB1 original', 'RCA-PLB2 original', 'RCA original', 'RCA-PDA original'\n",
    "\n",
    "\n",
    "\n",
    "'LCX', 'LCX-OM', 'LCX-OM *', 'LCX *', 'LCX-OM1 *', 'OM *', 'LCX-OM3 *', 'LCX-OM2 *', 'LCX-OM original', 'LCX original', 'OM2 *', 'LCX  *', 'LCX-OM  *', 'OM', 'OM1 *', 'LCX -OM3 *', 'LCX-OM*', 'LCX*', 'LCX-OM2', 'OM2', 'LCX2 *', 'LCX - OM2 *', 'LCX - OM *', 'OM3', 'OM1', 'LCX-OM3*', 'LCX-OM3', 'LCX-OM1', 'LCX-OM2*', 'OM3 *', 'OM3*',  'OM2*', 'OM4 *','LCX -OM2 *', 'LCX -OM1 *', 'OM4','LCX-OM4 *', , 'LCX-OM1*', 'OM*', 'OM original', \n",
    "\n",
    "'LCX  TO PDA *', 'LCX TO PLB', 'LCX TO PDA', 'LCX TO PDA *', 'LCX TO PDA2 *', 'LCX TO PDA*', 'LCX-OM4'\n",
    "\n",
    "'LCX-PLB', 'LCX-PLB *', 'LCX-PLB1', 'LCX-PLB2',  'LCX-PLB2 *'\n",
    "\n",
    "'LCX-PDA *', 'LCX-PDA', 'LCX-PDA2', 'LCX-PDA2 *', \n",
    "\n",
    "\n",
    "\n",
    "'PLB  *', 'PLB *', 'PLB2 *', 'PLB original', 'PLB2*', 'PLB1 *', 'PLB', 'PLB*', 'PLB3*', 'PLB2', 'PLB1', 'PLB3', 'PLB1*', 'RCA-PDA2*'\n",
    "\n",
    "'RIB *', 'RIB1 *', 'RIB2 *','RIB', 'RIB*','RIB2'\n",
    "\n",
    "'AM *', 'AM1 *', 'AM2 *', 'RCA-AM2', 'AM*', 'AM1', 'AM2', 'LB *',  'AM'\n",
    "\n",
    "\n",
    "### 500 images\n",
    "'Aorta-D1', 'Aorta-LCX', 'Aorta-D2',  'Aorta-OM graft*', 'Aorta-PDA graft *', 'Aorta-D1 graft *', 'Aorta-OM graft *','Aorta-LCX graft', 'Aorta-PDA graft', 'Aorta-D1 graft'\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 4000 images\n",
    "\n",
    "'78SSF', 'LOCALISER', 'Lt Septal Branch *', 'CT ARTERIES', 'Conus Artery *', 'AXIAL LUNG 2.5MM', 'LIMA-LAD graft', 'Aorta-LAD graft', 'RT Anomaly *', 'AXIAL MEDIASTINUM 2.5MM', 'Localiser', 'LIMA-LAD graft*', 'SScoreSerSav',  'PatientReport', 'ECG Report', 'Dose Report', 'ScreenSave', \n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 1400 images\n",
    "'OM-Branch of OM *', 'LCX-Branch of OM *', 'RIB-Branch of RIB *', 'Branch of PLB *', 'Branch 2 of PLB *', 'OM-Branch of OM',  'LCX-Branch of OM', 'RIB-Branch of RIB', 'OM-Branch OM *', 'LAD-Branch of D1', 'LCX-Branch of OM1 *', '81SSF', 'PLB3 *', 'LAD-Branch of D2 *', 'Branch of AM *', 'LAD-Branch of D1 *'\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "'PDLB'\n",
    "\n",
    ", 'PDA  *'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract PNG images from the MPRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mpr_name_to_record_name(mpr_name):\n",
    "    main_branches_dict = {\n",
    "        'LAD': ['LAD', 'LAD ', 'LAD Original', 'LAD original'],\n",
    "        'D-1':['LAD-D1 original', 'LAD-D1 Original', 'LAD-D1', 'LAD-D1 *', 'LAD -D1', 'LAD -D1', 'LAD - D1', 'D1'],\n",
    "        'D-2':['LAD-D2', 'LAD-D2 *', 'LAD-D2', '2LAD-D2', 'LAD -D2', 'LAD-D2 original', 'LAD -D2'],\n",
    "        'D-3': ['LAD-D3', 'LAD-D3 *', 'LAD-D3', 'LAD-D3 original', ],\n",
    "        'D-4': [ 'LAD - D4 *', 'LAD-D4', 'LAD-D4 *'],\n",
    "        'RCA': ['RCA', 'RCA *', 'RCA*', 'RCA original'],\n",
    "        'OM':['OM*', 'LCX-OM  *', 'OM *', 'OM', 'LCX-OM*', 'LCX - OM *', 'LCX-OM original', 'LCX-OM *', 'LCX-OM', 'OM original'],\n",
    "        'OM-1': ['LCX-OM1 *', 'OM1 *', 'OM1', 'LCX-OM1', 'LCX -OM1 *', 'LCX-OM1*'],\n",
    "        'OM-2': ['LCX-OM2 *', 'OM2 *', 'LCX-OM2', 'LCX - OM2 *', 'LCX -OM2 *', 'OM2*', 'LCX-OM2*'],\n",
    "        'OM-3': ['LCX-OM3 *', 'LCX -OM3 *', 'OM3',  'LCX-OM3*', 'LCX-OM3', 'OM3 *', 'OM3*'],\n",
    "        'OM-4': ['OM4 *', 'OM4', 'LCX-OM4 *'],\n",
    "        'LCX': ['LCX', 'LCX *', 'LCX original', 'LCX  *', 'LCX*']\n",
    "    }\n",
    "    \n",
    "    for key in main_branches_dict:\n",
    "        if mpr_name in main_branches_dict[key]:\n",
    "            return key\n",
    "\n",
    "def split_mpr_name(mpr_name):\n",
    "    return \\\n",
    "        \"\".join(mpr_name.split()).replace('*', '').replace('original', '') \\\n",
    "        .replace('LIMA-', '').replace('Branchof','').replace('TOPDA', '').replace('PDATO', '')\n",
    "\n",
    "def get_patient_dictionary(path_to_patient_folder):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns dict of different types of images in the folder of patient. \n",
    "    \n",
    "    Returns:\n",
    "        dict: key - type of images; value - list of DICOM files, which sorted in the ascending order with restepct to the\n",
    "                    depth of the image slice.\n",
    "    \"\"\"\n",
    "    patient_dict = {}\n",
    "    \n",
    "    dicom_file_names = os.listdir(path_to_patient_folder)\n",
    "    \n",
    "    for i in range(len(dicom_file_names)):\n",
    "        cur_dicom_obj = dicom.dcmread(os.path.join(path_to_patient_folder, dicom_file_names[i]))\n",
    "        \n",
    "        if cur_dicom_obj.SeriesDescription not in patient_dict.keys():\n",
    "            patient_dict[cur_dicom_obj.SeriesDescription] = []\n",
    "        patient_dict[cur_dicom_obj.SeriesDescription].append(cur_dicom_obj)\n",
    "        \n",
    "    # sort each type of images with respect to their depth in ascending order\n",
    "    for i in patient_dict:\n",
    "        patient_dict[i].sort(key=lambda x: x.InstanceNumber)\n",
    "    \n",
    "    return patient_dict\n",
    "\n",
    "def get_pixels_hu(list_of_imgs):\n",
    "    \"\"\"\n",
    "    Convert stack of the images into Houndsfeld units\n",
    "    \"\"\"\n",
    "    image = np.stack([s.pixel_array for s in list_of_imgs])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = list_of_imgs[0].RescaleIntercept\n",
    "    slope = list_of_imgs[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_data = r'D:\\coronaryProject\\dataset\\binary_classification_MPR\\images'\n",
    "# path_to_new_data = r'E:\\ONLY_LAD\\\\'\n",
    "path_to_data = r'/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/ONLY_MPR'\n",
    "path_to_new_data = r'/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/multibranch_dataset'\n",
    "list_of_patients = os.listdir(path_to_data)\n",
    "# patient_dictionary = get_patient_dictionary(path_to_data + '\\\\'+ list_of_patients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(list_of_patients))):\n",
    "    patient_dictionary = get_patient_dictionary(path_to_data + '/'+ list_of_patients[i])\n",
    "    splited_mpr_names_filtered = [map_mpr_name_to_record_name(x) for x in patient_dictionary.keys()]\n",
    "#     splited_mpr_names = [split_mpr_name(x) for x in patient_dictionary.keys()]\n",
    "#     splited_mpr_names_filtered = [split_mpr_name(x).replace('LAD-', '').replace('D','D-').replace('AD-', 'AD') for x in patient_dictionary.keys() \n",
    "#                                   if 'LAD' in split_mpr_name(x)]\n",
    "    dict_keys = list(patient_dictionary.keys())\n",
    "    \n",
    "    # change keys in the dict to the corresponding labels in the reports\n",
    "    for k in range(len(dict_keys)):\n",
    "#         patient_dictionary[split_mpr_name(key_element).replace('LAD-', '').replace('D','D-').replace('AD-', 'AD')] = \\\n",
    "#             patient_dictionary[key_element]\n",
    "        if splited_mpr_names_filtered[k]:\n",
    "            if dict_keys[k] in splited_mpr_names_filtered:\n",
    "                pass\n",
    "            else:\n",
    "                patient_dictionary[splited_mpr_names_filtered[k]] = patient_dictionary[dict_keys[k]]\n",
    "                del patient_dictionary[dict_keys[k]]\n",
    "        else:\n",
    "            del patient_dictionary[dict_keys[k]]\n",
    "\n",
    "    if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i])):\n",
    "        os.mkdir(os.path.join(path_to_new_data, list_of_patients[i]))\n",
    "\n",
    "    for key in patient_dictionary.keys():\n",
    "        \n",
    "        for dicom_file in patient_dictionary[key]:\n",
    "            if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i])):\n",
    "                os.mkdir(os.path.join(path_to_new_data, list_of_patients[i]))\n",
    "            \n",
    "            if not os.path.exists(os.path.join(path_to_new_data, list_of_patients[i], key)):\n",
    "                os.mkdir(os.path.join(path_to_new_data, list_of_patients[i], key))\n",
    "# #             dicom_file.save_as(os.path.join(path_to_new_data, \n",
    "# #                                             list_of_patients[i], \n",
    "# # #                                             key,\n",
    "# # #                                             list_of_patients[i]+'_'+str(dicom_file.InstanceNumber)\n",
    "# # #                                            )\n",
    "# # #                               )\n",
    "            cv2.imwrite(os.path.join(path_to_new_data, \n",
    "                                            list_of_patients[i], \n",
    "                                            key,\n",
    "                                            list_of_patients[i]+'_'+str(dicom_file.InstanceNumber)+'.png'\n",
    "                                           ),\n",
    "                        cv2.normalize(dicom_file.pixel_array, None, alpha = 0, \n",
    "                                      beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "                       )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_mpr_records(path_to_dataset, path_to_save):\n",
    "    \"\"\"\n",
    "    Copy all records from the dataset to path_to_save folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path_to_save):\n",
    "        os.mkdir(path_to_save)\n",
    "    folders = [x for x in os.listdir(path_to_dataset) if 'WITH RECONS ' in x]\n",
    "\n",
    "    for patient_name in os.listdir(os.path.join(path_to_dataset)):\n",
    "        files = os.listdir(os.path.join(path_to_dataset, patient_name))\n",
    "        files = [x for x in files if ('xlsx' in x) or ('doc' in x)]\n",
    "        files = files[0] if len(files)>0 else None\n",
    "        if files:\n",
    "            copyfile(os.path.join(path_to_dataset, patient_name, files), os.path.join(path_to_save, files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = r'd:\\test\\without_viewer'\n",
    "PATH_TO_SAVE = r'd:\\test\\records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mpr_records(PATH_TO_DATA, PATH_TO_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Merge Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_mpr_lad_name(mpr_name):\n",
    "    \"\"\"\n",
    "    Strip MPR name of the LAD artery. We do this step because the name in the doctor's report \n",
    "    is not equal to the name in the MPR. \n",
    "    \n",
    "    Returns:\n",
    "        - str: striped string\n",
    "    \"\"\"\n",
    "    return \"\".join(mpr_name.split()).replace('*', '').replace('original', '')\n",
    "\n",
    "def read_and_strip_record(path_to_record):\n",
    "    '''\n",
    "    Read record file and remove empty rows and rows with all NaNs.\n",
    "    \n",
    "    Returns:\n",
    "        - Pandas DataFrame: \n",
    "    '''\n",
    "    excel_file = pd.read_excel(path_to_record,index_col=None, header=None)\n",
    "    excel_file.dropna(how='all')\n",
    "    excel_file.rename(columns={0: 'a', 1: 'b'}, inplace=True)\n",
    "    excel_file = excel_file.fillna('  ')\n",
    "    excel_file = excel_file.replace('', '  ', regex=True)\n",
    "    excel_file = excel_file.drop(excel_file[excel_file['a'].str.isspace()].index)\n",
    "    return excel_file\n",
    "\n",
    "def get_lad_info_from_report(striped_record, artery_type):\n",
    "    \"\"\"\n",
    "    Takes striped(without any empty lines and NaNs) and returns info only about the certain artery type. \n",
    "    \n",
    "    Returns:\n",
    "        - list: each element is the string with some info about certain artery type\n",
    "    \"\"\"\n",
    "    lad_info = []\n",
    "    wether_add = False\n",
    "    lad_info.append(striped_record.iloc[0]['b'])\n",
    "    for ind, row_value in striped_record.iterrows():\n",
    "        \n",
    "        if wether_add and row_value['a'].isupper():\n",
    "            break\n",
    "        if wether_add:\n",
    "            lad_info.append(row_value['a'])\n",
    "        \n",
    "        if artery_type in row_value['a']:\n",
    "            wether_add = True\n",
    "    return lad_info\n",
    "\n",
    "def get_level_of_stenosis_from_string(artery_info):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        - list of str: each element is the string with percentage of stenosis. \n",
    "    \"\"\"\n",
    "    return [x.strip() for x in re.findall(r'.\\d{1,3}.?\\d{1,3}\\%', artery_info)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_records = r'/home/petryshak/CoronaryArteryPlaqueIdentification/data/reports'\n",
    "list_of_files = os.listdir(path_to_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_lad_df = pd.DataFrame(columns=['PATIENT_ID','PROXIMAL', 'MID', 'DISTAL', 'D-1', 'D-2', 'D-3', 'D-4'])\n",
    "\n",
    "for i in tqdm(range(len(list_of_files))):\n",
    "    cur_file = read_and_strip_record(os.path.join(path_to_records, list_of_files[i]))\n",
    "    cur_patient_lad_info = get_lad_info_from_report(cur_file, 'LEFT ANTERIOR')\n",
    "    \n",
    "    new_row = pd.Series(#[Nan,Nan,Nan,Nan,Nan,Nan,Nan,Nan],\n",
    "                        ['-','-','-','-','-','-','-','-'],\n",
    "                        index=extracted_lad_df.columns)\n",
    "    new_row['PATIENT_ID'] = cur_patient_lad_info[0]\n",
    "    cur_patient_lad_info.pop(0)\n",
    "    list_of_lda_branches = list(extracted_lad_df.columns)\n",
    "    \n",
    "    for line_info in cur_patient_lad_info:\n",
    "        \n",
    "        artery_area_name = [x for x in list_of_lda_branches \n",
    "                            if x in line_info or x.lower() in line_info or x.title() in line_info]\n",
    "        if len(artery_area_name) >=1:\n",
    "            artery_area_name = artery_area_name[0]\n",
    "        else:\n",
    "            continue\n",
    "        stenosis_score = get_level_of_stenosis_from_string(line_info)\n",
    "        stenosis_score =  stenosis_score[0] if stenosis_score else 'NORMAL'\n",
    "        new_row.loc[artery_area_name] = stenosis_score\n",
    "    extracted_lad_df = extracted_lad_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_lad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_lad_df.to_excel('lad_reports.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Remove text from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text(img):\n",
    "    mask = cv2.threshold(img, 250, 255, cv2.THRESH_BINARY)[1][:,:,0]\n",
    "    dilated_mask = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)))\n",
    "    dst = cv2.inpaint(img, dilated_mask, 5, cv2.INPAINT_NS)\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/multibranch_dataset'\n",
    "patients_names = os.listdir(PATH_TO_DATA)\n",
    "\n",
    "for patient_name in tqdm(patients_names):\n",
    "    images_types = os.listdir(os.path.join(PATH_TO_DATA, patient_name))\n",
    "    \n",
    "    for img_type in images_types:\n",
    "        images_names = os.listdir(os.path.join(PATH_TO_DATA, patient_name, img_type))\n",
    "        filtered_imgs = [x for x in images_names if '_text_deleted' in x]\n",
    "        if len(filtered_imgs) > 0:\n",
    "            continue\n",
    "            \n",
    "        for img_name in images_names:\n",
    "            img_path = os.path.join(PATH_TO_DATA, patient_name, img_type, img_name)\n",
    "            cur_img = cv2.imread(img_path)\n",
    "            img_without_text = remove_text(cur_img)\n",
    "            cv2.imwrite(img_path, img_without_text)\n",
    "#             cv2.imwrite(os.path.join(PATH_TO_DATA, patient_name, img_type, img_name.split('.')[0] + '_text_deleted.png'), img_without_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_for_patient_lad(lad_segment, reports, patient_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "        get_label_for_patient('LAD', reports, 'DDJ261Z' )\n",
    "\n",
    "    \"\"\"\n",
    "    classes_to_positive = ['<25%', 'NORMAL', '-']\n",
    "\n",
    "    if lad_segment == 'LAD':\n",
    "        curr_section_label = reports.loc[reports['PATIENT_ID'] == patient_id][['MID', 'PROXIMAL', 'DISTAL']].iloc[0]\n",
    "        stenosis_score = [x for x in curr_section_label if x not in classes_to_positive]\n",
    "        label = 1 if len(stenosis_score) > 0 else 0\n",
    "        return label, '___'.join(curr_section_label.values)\n",
    "        \n",
    "    else:\n",
    "        curr_section_label =  reports.loc[reports['PATIENT_ID'] == patient_id][lad_segment].iloc[0]\n",
    "        label = 0 if curr_section_label in classes_to_positive else 1    \n",
    "        return label, curr_section_label\n",
    "\n",
    "def get_label_for_patient(artery_segment, reports, patient_id):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "        get_label_for_patient('LAD', reports, 'DDJ261Z' )\n",
    "\n",
    "    \"\"\"    \n",
    "    classes_to_positive = ['<25%', 'NORMAL', '-']\n",
    "    curr_section_label = reports.loc[reports['PATIENT_ID'] == patient_id][artery_segment].iloc[0]\n",
    "    label = 0 if curr_section_label in classes_to_positive else 1    \n",
    "    return label, curr_section_label\n",
    "\n",
    "\n",
    "    \n",
    "def get_labels(path_to_patient, reports):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        - dict: key(str) - type of the artery, value(int) - label(0 or 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    types_of_images = os.listdir(path_to_patient)\n",
    "    types_of_images = [x for x in types_of_images if x in list(reports.columns)]\n",
    "    patient_name = [x for x in path_to_patient.split('/') if len(x) > 0][-1]\n",
    "    labels_dict = {}\n",
    "    \n",
    "    for i in range(len(types_of_images)):\n",
    "        labels_dict[types_of_images[i]] = get_label_for_patient(types_of_images[i], reports, patient_name)\n",
    "        \n",
    "    return dict(filter(lambda elem: elem[1][1] != '-', labels_dict.items()))\n",
    "\n",
    "\n",
    "def get_imgs_names_to_the_labels(path_to_patient, labels_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - dict: key - branch of artery(str), value - label(int) 0 or 1.   \n",
    "    Returns:\n",
    "        - dict: key - label(int) 0 or 1, value(list) list of images, belong to the labelT\n",
    "    \"\"\"\n",
    "    img_labels = {}\n",
    "    for key in labels_dict.keys():\n",
    "        list_of_images = os.listdir(os.path.join(path_to_patient, key))\n",
    "        \n",
    "        if labels_dict[key] in img_labels:\n",
    "            new_key = (key, labels_dict[key][1], labels_dict[key][0])\n",
    "#             img_labels[labels_dict[key]]+= list_of_images\n",
    "            img_labels[new_key] += list_of_images\n",
    "        else:\n",
    "            new_key = (key, labels_dict[key][1], labels_dict[key][0])\n",
    "            img_labels[new_key] = list_of_images\n",
    "\n",
    "#             img_labels[labels_dict[key]] = list_of_images\n",
    "            \n",
    "    return img_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D-1': (0, 'NORMAL'),\n",
       " 'D-2': (0, 'NORMAL'),\n",
       " 'D-3': (0, 'NORMAL'),\n",
       " 'OM-2': (0, 'NORMAL'),\n",
       " 'RCA': (0, 'NORMAL')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_labels('/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches/train/imgs/CTCAZOF20051940',\n",
    "           reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) rename name of the patient's folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MERGED_CSV = '/home/petryshak/CoronaryArteryPlaqueIdentification/notebooks/ExtractLabels/lad_rca_lcx.xlsx'\n",
    "\n",
    "PATH_TO_RENAME = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/multibranch_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.read_excel(PATH_TO_MERGED_CSV, index_col=0)\n",
    "# file_names = os.listdir(PATH_TO_RENAME)\n",
    "file_names_reports = list(reports['PATIENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_values = []\n",
    "exceptions_which_should_be_added = \\\n",
    "    [\n",
    "     '348 CTCAGRH27071943',\n",
    "     '349 CTCANGM17081945',\n",
    "     '350 CTCATRH10061944',\n",
    "     '351 CTCAGRH27071943',\n",
    "     '353 CTCANGM17081945',\n",
    "     '371 CTCATRH10061944'\n",
    "    ]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    if file_names[i] in exceptions_which_should_be_added:\n",
    "        continue\n",
    "    \n",
    "    splited_value = file_names[i].split(' ')\n",
    "    if len(splited_value[0]) == 4 or file_names[i] in exceptions_which_should_be_added:\n",
    "        new_values.append(file_names[i])\n",
    "    else:\n",
    "        os.rename(os.path.join(PATH_TO_RENAME, file_names[i]), os.path.join(PATH_TO_RENAME, splited_value[1]))\n",
    "        new_values.append(splited_value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Rename all images per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/all_branches/multibranch_dataset'\n",
    "\n",
    "patients_names = os.listdir(PATH_TO_DATA)\n",
    "\n",
    "for patient_name in tqdm(patients_names):\n",
    "    images_types = os.listdir(os.path.join(PATH_TO_DATA, patient_name))\n",
    "    \n",
    "    for img_type in images_types:\n",
    "        images_names = os.listdir(os.path.join(PATH_TO_DATA, patient_name, img_type))\n",
    "        for img_name in images_names:\n",
    "            os.rename(os.path.join(PATH_TO_DATA, patient_name, img_type, img_name),\n",
    "                      os.path.join(PATH_TO_DATA, patient_name, img_type, img_type+'_'+'_'.join(img_name.split(' '))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Train/Val/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dataset_part(dataset_part_name, patients_list, path_to_data , path_to_move):\n",
    "    \"\"\"\n",
    "    Takes patient list and move to new subdataset.\n",
    "    \n",
    "    Args:\n",
    "        - dataset_part_name(str): name of the new subpart of the dataset\n",
    "        - patients_list: list of the patient, which sould be moved\n",
    "        - path_to_data: dataset, from which we take the patient folders\n",
    "        - path_to_move: path, where create new dataset\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.join(path_to_move, dataset_part_name)):\n",
    "        os.mkdir(os.path.join(path_to_move, dataset_part_name))\n",
    "    \n",
    "    for i in range(len(patients_list)):\n",
    "        shutil.move(os.path.join(path_to_data, patients_list[i]), os.path.join(path_to_move, dataset_part_name, patients_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "349 CTCANGM17081945 - deleted because it empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_part = [\n",
    "    'CTCAZHX30011957',\n",
    "    'CTCAYOG08091955',\n",
    "    'CTCAYOA13121966',\n",
    "    'CTCATHJ17011957',\n",
    "    'CTCAPHD16081938',\n",
    "    'CTCASIP30041975',\n",
    "    'CTCASTW15121946',\n",
    "    'CTCATKR01031953',\n",
    "    'CTCAVAH09071948',\n",
    "    'CTCAZDV13081958',\n",
    "]\n",
    "\n",
    "val_part = [\n",
    "    '1006 CTCA1961',\n",
    "    '1007 CTCA1959',\n",
    "    '1009 CTCA1955',\n",
    "    '1027 CTCA1965',\n",
    "    'CTCAAGK05031979',\n",
    "    'CTCAANM18021961',\n",
    "    '1001 CTCA1947',\n",
    "    '1002 CTCA1955',\n",
    "    '1060 CTCA1959',\n",
    "    '1038 CTCA1979',\n",
    "    '1045 CTCA1950',  \n",
    "    'CTCAWUK05041963',\n",
    "    'CTCASTR17021954',\n",
    "    'CTCASTS01111969',\n",
    "    'CTCATUQ02091955',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches/train'\n",
    "PATH_TO_MOVE = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches'\n",
    "DATASET_PART_NAME = 'test'\n",
    "move_dataset_part(DATASET_PART_NAME, test_part, PATH_TO_DATA, PATH_TO_MOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches/train'\n",
    "PATH_TO_MOVE = '/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches'\n",
    "DATASET_PART_NAME = 'val'\n",
    "move_dataset_part(DATASET_PART_NAME, val_part, PATH_TO_DATA, PATH_TO_MOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Create final dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir('/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_only_lad/train')\n",
    "val_files = os.listdir('/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_only_lad/val')\n",
    "test_files = os.listdir('/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_only_lad/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>REPORT_ID</th>\n",
       "      <th>LAD</th>\n",
       "      <th>D-1</th>\n",
       "      <th>D-2</th>\n",
       "      <th>D-3</th>\n",
       "      <th>RCA</th>\n",
       "      <th>OM</th>\n",
       "      <th>OM-1</th>\n",
       "      <th>OM-2</th>\n",
       "      <th>OM-3</th>\n",
       "      <th>LCX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>CTCALAN04091968</td>\n",
       "      <td>CTCALAN04091968</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1058 CTCA1956</td>\n",
       "      <td>1058 CTCA1956</td>\n",
       "      <td>50-70%</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>CTCABOJ29051945</td>\n",
       "      <td>CTCABOJ29051945</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>CTCAGRC24011965</td>\n",
       "      <td>CTCAGRC24011965</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>CTCAGAR01101953</td>\n",
       "      <td>CTCAGAR01101953</td>\n",
       "      <td>25%</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>-</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PATIENT_ID        REPORT_ID     LAD     D-1     D-2     D-3     RCA  \\\n",
       "739  CTCALAN04091968  CTCALAN04091968  NORMAL       -       -       -  NORMAL   \n",
       "740    1058 CTCA1956    1058 CTCA1956  50-70%  NORMAL       -       -  NORMAL   \n",
       "741  CTCABOJ29051945  CTCABOJ29051945  NORMAL  NORMAL  NORMAL       -  NORMAL   \n",
       "742  CTCAGRC24011965  CTCAGRC24011965  NORMAL  NORMAL  NORMAL  NORMAL  NORMAL   \n",
       "743  CTCAGAR01101953  CTCAGAR01101953     25%  NORMAL       -       -  NORMAL   \n",
       "\n",
       "    OM    OM-1    OM-2    OM-3     LCX  \n",
       "739  -  NORMAL       -       -  NORMAL  \n",
       "740  -  NORMAL       -       -  NORMAL  \n",
       "741  -  NORMAL       -       -  NORMAL  \n",
       "742  -  NORMAL       -       -  NORMAL  \n",
       "743  -  NORMAL  NORMAL  NORMAL  NORMAL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 1/15 [00:00<00:02,  5.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 2/15 [00:00<00:02,  5.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 3/15 [00:00<00:02,  5.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 4/15 [00:00<00:02,  5.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 5/15 [00:00<00:01,  5.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 6/15 [00:01<00:01,  5.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 7/15 [00:01<00:01,  5.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 8/15 [00:01<00:01,  5.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 9/15 [00:02<00:01,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 10/15 [00:02<00:01,  3.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 12/15 [00:02<00:00,  4.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 13/15 [00:02<00:00,  4.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 14/15 [00:02<00:00,  5.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "PATH_TO_DATA = r'/home/petryshak/CoronaryArteryPlaqueIdentification/data/binary_classification_all_branches/val/imgs'\n",
    "list_of_patients = os.listdir(PATH_TO_DATA)\n",
    "\n",
    "labels_csv = pd.DataFrame(columns=['PATIENT_NAME', 'IMG_NAME', 'STENOSIS_SCORE', 'ARTERY_SECTION', 'MPR_VIEWPOINT_INDEX', 'LABEL'])\n",
    "\n",
    "for i in tqdm(range(len(list_of_patients))):\n",
    "#     if i == 0:\n",
    "#         continue\n",
    "    if list_of_patients[i] in '1006 CTCA1961':#fif:\n",
    "        continue\n",
    "    labels = get_labels(os.path.join(PATH_TO_DATA, list_of_patients[i]), reports)\n",
    "    dict_labels_images = get_imgs_names_to_the_labels(os.path.join(PATH_TO_DATA, list_of_patients[i]), labels)\n",
    "\n",
    "    for key in dict_labels_images:\n",
    "        each_ind = 0\n",
    "        for j in range(len(dict_labels_images[key])):\n",
    "#             if each_ind % 3 == 0:\n",
    "            mpr_veiwpoint_index = dict_labels_images[key][j].strip('.png').split('_')[-1]\n",
    "            new_row = pd.Series(\n",
    "                                [\n",
    "                                    list_of_patients[i],\n",
    "                                    dict_labels_images[key][j],\n",
    "                                    key[1],\n",
    "                                    key[0],\n",
    "                                    mpr_veiwpoint_index,\n",
    "                                    key[2]\n",
    "                                ],\n",
    "                                index=labels_csv.columns)\n",
    "            labels_csv = labels_csv.append(new_row, ignore_index=True)\n",
    "#             each_ind+=1            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv.to_excel('val_labels_with_normal_and_minimal_stenosis_level.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35266.666666666664"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_csv['STENOSIS_SCORE'].shape[0] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORMAL    700\n",
       "<25%      500\n",
       "25-50%    450\n",
       "25%        50\n",
       "50-70%     50\n",
       "Name: STENOSIS_SCORE, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(labels_csv['STENOSIS_SCORE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_NAME</th>\n",
       "      <th>IMG_NAME</th>\n",
       "      <th>STENOSIS_SCORE</th>\n",
       "      <th>ARTERY_SECTION</th>\n",
       "      <th>MPR_VIEWPOINT_INDEX</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTCATHR12061965</td>\n",
       "      <td>LAD_366_CTCATHR12061965_24.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LAD</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTCATHR12061965</td>\n",
       "      <td>LAD_366_CTCATHR12061965_16.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LAD</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTCATHR12061965</td>\n",
       "      <td>LAD_366_CTCATHR12061965_6.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LAD</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTCATHR12061965</td>\n",
       "      <td>LAD_366_CTCATHR12061965_11.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LAD</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTCATHR12061965</td>\n",
       "      <td>LAD_366_CTCATHR12061965_7.png</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LAD</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PATIENT_NAME                        IMG_NAME STENOSIS_SCORE  \\\n",
       "0  CTCATHR12061965  LAD_366_CTCATHR12061965_24.png         NORMAL   \n",
       "1  CTCATHR12061965  LAD_366_CTCATHR12061965_16.png         NORMAL   \n",
       "2  CTCATHR12061965   LAD_366_CTCATHR12061965_6.png         NORMAL   \n",
       "3  CTCATHR12061965  LAD_366_CTCATHR12061965_11.png         NORMAL   \n",
       "4  CTCATHR12061965   LAD_366_CTCATHR12061965_7.png         NORMAL   \n",
       "\n",
       "  ARTERY_SECTION MPR_VIEWPOINT_INDEX LABEL  \n",
       "0            LAD                  24     0  \n",
       "1            LAD                  16     0  \n",
       "2            LAD                   6     0  \n",
       "3            LAD                  11     0  \n",
       "4            LAD                   7     0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif = []\n",
    "for i in range(len(list_of_patients)):\n",
    "    if list_of_patients[i] not in list(reports['PATIENT_ID']):\n",
    "        fif.append(list_of_patients[i])\n",
    "#         print(list_of_patients[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1006 CTCA1961']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
